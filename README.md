# ğŸ“Š PySpark + SharePoint + Databricks  
## Exemplo prÃ¡tico de Engenharia de Dados (end-to-end)

---

## ğŸ¯ Objetivo do Projeto

Este notebook foi desenvolvido com **finalidade demonstrativa**, com o objetivo de **mostrar como construir um pipeline em PySpark que consome dados diretamente do SharePoint**, realiza tratamentos e persiste os dados em uma **tabela Delta no Databricks (Lakehouse)**.

O foco nÃ£o Ã© apenas o dado em si, mas **o COMO fazer**:
- Como autenticar no SharePoint de forma segura
- Como acessar arquivos (Excel) via **Microsoft Graph API**
- Como integrar Pandas + Spark de forma eficiente
- Como aplicar boas prÃ¡ticas de **Engenharia de Dados em PySpark**

Este projeto serve como **referÃªncia tÃ©cnica reutilizÃ¡vel** para cenÃ¡rios reais de ingestÃ£o de dados corporativos.

---

## ğŸ§  O que este cÃ³digo demonstra na prÃ¡tica

âœ” IntegraÃ§Ã£o entre **SharePoint e Databricks**  
âœ” Uso de **Microsoft Graph API** para leitura de arquivos  
âœ” ConversÃ£o de dados externos em **Spark DataFrames**  
âœ” PadronizaÃ§Ã£o e enriquecimento de dados  
âœ” AplicaÃ§Ã£o de regras de negÃ³cio  
âœ” PersistÃªncia governada em **Delta Lake**  

---

## ğŸ—ï¸ Arquitetura do Fluxo

**SharePoint (Excel)**  
â¬‡  
**Microsoft Graph API**  
â¬‡  
**Pandas (leitura inicial)**  
â¬‡  
**PySpark (transformaÃ§Ãµes)**  
â¬‡  
**Delta Table (Databricks Lakehouse)**

---

## ğŸ” AutenticaÃ§Ã£o e SeguranÃ§a

O acesso ao SharePoint Ã© feito via **Azure AD App Registration**, utilizando:
- `CLIENT_ID`
- `CLIENT_SECRET`
- `TENANT_ID`

As credenciais sÃ£o armazenadas de forma segura em **Databricks Secrets**, seguindo boas prÃ¡ticas de seguranÃ§a e governanÃ§a.

---

## ğŸ§© Etapas do Pipeline (passo a passo)

### 1ï¸âƒ£ PreparaÃ§Ã£o do ambiente
- InstalaÃ§Ã£o de dependÃªncias (`openpyxl`)
- ImportaÃ§Ã£o de bibliotecas necessÃ¡rias
- ReinicializaÃ§Ã£o do kernel Python

### 2ï¸âƒ£ AutenticaÃ§Ã£o no Microsoft Graph
- GeraÃ§Ã£o de token OAuth2 com MSAL
- ConfiguraÃ§Ã£o dos headers HTTP

### 3ï¸âƒ£ Descoberta do SharePoint
- LocalizaÃ§Ã£o do `site_id`
- IdentificaÃ§Ã£o do `drive_id` correto (Documentos / Shared Documents)

### 4ï¸âƒ£ Leitura do arquivo Excel
- Download do arquivo diretamente do SharePoint
- Leitura via Pandas
- Fallback automÃ¡tico de abas, quando necessÃ¡rio

### 5ï¸âƒ£ Tratamento e padronizaÃ§Ã£o
- NormalizaÃ§Ã£o de nomes de colunas
- Ajustes de nomenclatura para compatibilidade
- CriaÃ§Ã£o de colunas derivadas
- PadronizaÃ§Ã£o de chaves (ex.: zero Ã  esquerda)

### 6ï¸âƒ£ ConversÃ£o para Spark
- TransformaÃ§Ã£o de Pandas DataFrame â†’ Spark DataFrame
- Garantia de tipos e estrutura

### 7ï¸âƒ£ PersistÃªncia no Lakehouse
- Escrita em formato **Delta**
- Modo `overwrite` com `overwriteSchema`
- AtualizaÃ§Ã£o controlada da tabela final

---

## ğŸ“¦ Output Final

ğŸ“Œ **Tabela Delta criada/atualizada:**
{catalog}.planejamento.dim_de_para_categoria

Essa tabela fica pronta para:
- Consumo analÃ­tico
- Dashboards (Power BI, Databricks SQL)
- Pipelines downstream
- AutomaÃ§Ã£o e IA

---

## ğŸ§ª Por que este exemplo Ã© importante?

Porque **SharePoint Ã© uma fonte extremamente comum** em ambientes corporativos â€” e raramente bem tratada do ponto de vista de engenharia.

Este cÃ³digo mostra como:
- Sair do â€œdownload manualâ€
- Automatizar ingestÃµes recorrentes
- Criar pipelines escalÃ¡veis e governados
- Transformar arquivos operacionais em **ativos de dados**

---

## ğŸ” ReutilizaÃ§Ã£o

O padrÃ£o apresentado aqui pode ser facilmente adaptado para:
- Outros arquivos Excel ou CSV
- Outras bibliotecas do SharePoint
- Diferentes domÃ­nios de negÃ³cio
- Pipelines produtivos ou provas de conceito (PoC)

---

## ğŸ‘©â€ğŸ’» Autoria & Contexto

Este projeto faz parte do meu **portfÃ³lio em Engenharia de Dados**, com foco em:
- Databricks
- PySpark
- IntegraÃ§Ãµes corporativas
- AutomaÃ§Ã£o e IA aplicada a dados


## ğŸ—ï¸ Diagrama de Arquitetura â€” SharePoint â†’ Databricks (Lakehouse)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SharePoint       â”‚
â”‚  (Excel / Tabela)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ Microsoft Graph API
          â”‚ (OAuth2 + Azure AD)
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Databricks       â”‚
â”‚  Notebook PySpark  â”‚
â”‚                    â”‚
â”‚ â€¢ AutenticaÃ§Ã£o     â”‚
â”‚ â€¢ Download Excel   â”‚
â”‚ â€¢ Pandas           â”‚
â”‚ â€¢ PySpark          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ TransformaÃ§Ãµes
          â”‚ PadronizaÃ§Ã£o
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Delta Lake       â”‚
â”‚ (Lakehouse Table)  â”‚
â”‚ dim_de_para_categoria â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ Consumo AnalÃ­tico
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BI / Analytics     â”‚
â”‚ Power BI / SQL     â”‚
â”‚ AutomaÃ§Ã£o / IA     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


![Diagrama de Arquitetura](https://github.com/user-attachments/assets/b6f649f1-8722-4f69-afe3-113181a56daa)


